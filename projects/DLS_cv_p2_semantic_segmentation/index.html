<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h1 id="задача">Задача</h1> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Typical_cnn/800px-Typical_cnn-480.webp 480w,https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Typical_cnn/800px-Typical_cnn-800.webp 800w,https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Typical_cnn/800px-Typical_cnn-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Typical_cnn.png/800px-Typical_cnn.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Aphex34" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>В данном проекте нам предстоит решить задачу сегментации медицинских снимков. В нашем распоряжении датасет <a href="https://www.fc.up.pt/addi/ph2%20database.html" rel="external nofollow noopener" target="_blank"><em>ADDI project</em></a>. В нём содержатся фотографии различных поражений кожи: меланомы и родинок. Однако мы будем заниматься не классификацией, а сегментацией изображений, т.е. разделением изображений на несколько сегментов для упрощения последующего анализа и обработки. Проще говоря, нам необходимо обучить модель, которая сможет для каждого пикселя исходного изображения определить: изображена на нём родинка, либо просто участок кожи.</p> <p>Попробуем создать и обучить две модели для семантической сегментации:</p> <ul> <li> <a href="https://arxiv.org/pdf/1511.00561.pdf" rel="external nofollow noopener" target="_blank"><em>SegNet</em></a>, часто используемую на практике модель, базирующуюся на архитектуре <em>VGG16</em> для формирования энкодера;</li> <li> <a href="https://arxiv.org/pdf/1505.04597.pdf" rel="external nofollow noopener" target="_blank"><em>U-Net</em></a>, модель, изначально создававшуюся и оптимизированную для семантической сегментации медицинских изображений.</li> </ul> <p>В качестве эксперимента реализуем также несколько модификаций оригинальной модели <em>U-Net</em>: заменим некоторые слои на их аналоги и посмотрим, скажется ли это на результате.</p> <p>Также попробуем реализовать несколько функций потерь, чтобы оценить, насколько они влияют на конечный результат сегментации.</p> <h1 id="ноутбук">Ноутбук</h1> <p><a href="https://github.com/onixlas/DS_portfolio/blob/main/DLS_p2_semantic_segmentation/dls_p2_semantic_segmentation.ipynb" rel="external nofollow noopener" target="_blank">(ноутбук проекта)</a></p> <h1 id="выводы">Выводы</h1> <p>В данном проекте мы решали задачу сегментации медицинских снимков. В нашем распоряжении датасет <a href="https://www.fc.up.pt/addi/ph2%20database.html" rel="external nofollow noopener" target="_blank"><em>ADDI project</em></a>. В нём содержатся фотографии различных поражений кожи: меланомы и родинок.</p> <p>Мы начали с того, что реализовали модель на основе архитектуры <a href="https://arxiv.org/pdf/1511.00561.pdf" rel="external nofollow noopener" target="_blank"><em>SegNet</em></a>, в качестве функции потерь использовалась бинарную кросс-энтропию. Мы также реализовали несколько дополнительных функций потерь, чтобы проверить, как они скажутся на обучаемости модели.</p> <p>Каждая модель обучалась в течение 40 эпох с оптимизатором <em>AdamW</em>. В качестве метрики мы использовали <a href="https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D1%8D%D1%84%D1%84%D0%B8%D1%86%D0%B8%D0%B5%D0%BD%D1%82_%D0%96%D0%B0%D0%BA%D0%BA%D0%B0%D1%80%D0%B0" rel="external nofollow noopener" target="_blank">коэффициент Жаккара <em>(IoU)</em></a>.</p> <p>Сведём данные по значениям метрики IoU на последних эпохах обучения для всех функций потерь.</p> <table> <thead> <tr> <th>Модель</th> <th>Функция потерь</th> <th>IoU (train)</th> <th>IoU (valid)</th> </tr> </thead> <tbody> <tr> <td>SegNet</td> <td>BCE loss</td> <td>0.8291</td> <td>0.7981</td> </tr> <tr> <td>SegNet</td> <td>Dice loss</td> <td>0.7965</td> <td>0.7892</td> </tr> <tr> <td>SegNet</td> <td>Focal loss</td> <td>0.8061</td> <td>0.7680</td> </tr> <tr> <td>SegNet</td> <td>WSR loss</td> <td>0.7587</td> <td>0.8007</td> </tr> </tbody> </table> <p>Видно, что для всех функций потерь удалось достичь достаточно неплохих значений метрики <em>IoU</em>. Наилучшие результаты показала модель с функцией потерь WSR loss, однако результаты в целом различаются не очень сильно.</p> <p>Из построенных в рамках проекта графиков видно, что 40 эпох хватило, чтобы достичь сходимости для всех функций потерь. При этом стоит отметить, что для функции потерь <em>Dice loss</em> значения на графиках сходились стабильнее всего.</p> <p>Также мы обучили несколько моделей с различными вариациями архитектуры <a href="https://arxiv.org/abs/1505.04597" rel="external nofollow noopener" target="_blank"><em>U-Net</em></a>.</p> <p>Первую модель мы реализовали в соответствии с оригинальной статьёй. Для пулинга (уменьшения размера изображений внутри сети) использовался <em>MaxPooling</em>, для апсамплинга (увеличения размера изображений внутри сети) - слои с обратной свёрткой <em>(ConvTranspose)</em>.</p> <p>Во второй модели для пулинга также использовался <em>MaxPooling</em>, а для апсмаплинга был применён <em>nearest-neighbor Upsampling</em>.</p> <p>В третьей модели для пулинга были применены свёрточные слои.</p> <p>Все три модели обучались с функцией потерь BCE. Для каждой модели рассчитывался коэффициент <em>IoU</em>.</p> <p>Сведём результаты экспериментов с U-Net в единую таблицу.</p> <table> <thead> <tr> <th>Модель</th> <th>Функция потерь</th> <th>IoU (train)</th> <th>IoU (valid)</th> </tr> </thead> <tbody> <tr> <td>U-Net</td> <td>BCE loss</td> <td>0.8668</td> <td>0.8016</td> </tr> <tr> <td>U-Net + upsampling</td> <td>BCE loss</td> <td>0.8197</td> <td>0.8299</td> </tr> <tr> <td>U-Net + convpool</td> <td>BCE loss</td> <td>0.7938</td> <td>0.8327</td> </tr> </tbody> </table> <p>Видно, что в рамках наших экспериментов значения метрики <em>IoU</em> для различных модификаций архитектуры <em>U-Net</em> несколько выше, чем для модели <em>SegNet</em>. Наилучшего значения метрики на валидации удалось добиться при использовании свёрточного пуллинга.</p> <p>Модели на основе <em>U-Net</em> показывают достаточно высокие значения метрики <em>IoU</em>, но они сходятся несколько хуже моделей на основе архитектуры <em>SegNet</em>. Наилучшую сходимость показала модель со свёрточным пуллингом.</p> <p>Из проведённых экспериментов видно, что на результаты модели оказывают существенное влияние различные факторы, в том числе выбор функции потерь и нюансов архитектуры. При их выборе следует учитывать несколько факторов: наилучшие значения метрики, стабильность сходимости модели, скорость обучения (количество обучаемых параметров модели). В рамках нашей задачи, если предположить, что заказчику важнее всего значение метрики <em>IoU</em>, наилучший результат продемонстрировала модель на основе архитектуры <em>U-Net</em> со свёрточным пуллингом.</p> <p>В качестве модели мы выбрали <a href="https://arxiv.org/abs/1611.05431" rel="external nofollow noopener" target="_blank"><em>ResNext</em></a>. Данная модификация архитектуры <em>RexNet</em> была предложена в 2017 году и продемонстрировала хорошие результаты на соревновании <em>ImageNet</em>. В качестве направления дальнейшего развития данного проекта можно попробовать обучить модели с различными архитектурами (<em>DenseNet</em>, <em>ElasticNet</em> и т.д.) и сравнить их результаты.</p> <p>Обучение происходило с оптимизатором <em>AdamW</em> в течение 20 эпох. В качестве функции потерь была выбрана кросс-энтропия.</p> <p>На каждой эпохе обучения мы фиксировали значение функции потерь и метрики <em>F1</em>.</p> <p>После обучения мы получили предсказания на тестовых данных и загрузили их на платформу <em>kaggle</em>. Результирующее значение метрики <em>F1</em> на тестовой выборке (0.993) соответствует максимальному балу за данную задачу.</p> </body></html>