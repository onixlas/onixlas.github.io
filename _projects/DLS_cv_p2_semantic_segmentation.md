---
layout: page
title: Семантическая сегментация 
description: Мы будем решить задачу сегментации медицинских снимков. В нашем распоряжении датасет ADDI project. В нём содержатся фотографии различных поражений кожи: меланомы и родинок. Однако мы будем заниматься не классификацией, а сегментацией изображений, т.е. разделением изображений на несколько сегментов для упрощения последующего анализа и обработки.
img: https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Typical_cnn.png/800px-Typical_cnn.png
importance: 1
category: образование
related_publications: false
---

# Задача

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Typical_cnn.png/800px-Typical_cnn.png" title="Aphex34" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

В данном проекте нам предстоит решить задачу сегментации медицинских снимков. В нашем распоряжении датасет [_ADDI project_](https://www.fc.up.pt/addi/ph2%20database.html). В нём содержатся фотографии различных поражений кожи: меланомы и родинок. Однако мы будем заниматься не классификацией, а сегментацией изображений, т.е. разделением изображений на несколько сегментов для упрощения последующего анализа и обработки. Проще говоря, нам необходимо обучить модель, которая сможет для каждого пикселя исходного изображения определить: изображена на нём родинка, либо просто участок кожи.

Попробуем создать и обучить две модели для семантической сегментации:

- [_SegNet_](https://arxiv.org/pdf/1511.00561.pdf), часто используемую на практике модель, базирующуюся на архитектуре _VGG16_ для формирования энкодера;
- [_U-Net_](https://arxiv.org/pdf/1505.04597.pdf), модель, изначально создававшуюся и оптимизированную для семантической сегментации медицинских изображений.

В качестве эксперимента реализуем также несколько модификаций оригинальной модели _U-Net_: заменим некоторые слои на их аналоги и посмотрим, скажется ли это на результате.

Также попробуем реализовать несколько функций потерь, чтобы оценить, насколько они влияют на конечный результат сегментации.

# Ноутбук

[(ноутбук проекта)](https://github.com/onixlas/DS_portfolio/blob/main/DLS_p2_semantic_segmentation/dls_p2_semantic_segmentation.ipynb)

# Выводы

В данном проекте мы решали задачу сегментации медицинских снимков. В нашем распоряжении датасет [_ADDI project_](https://www.fc.up.pt/addi/ph2%20database.html). В нём содержатся фотографии различных поражений кожи: меланомы и родинок.

Мы начали с того, что реализовали модель на основе архитектуры [_SegNet_](https://arxiv.org/pdf/1511.00561.pdf), в качестве функции потерь использовалась бинарную кросс-энтропию. Мы также реализовали несколько дополнительных функций потерь, чтобы проверить, как они скажутся на обучаемости модели.

Каждая модель обучалась в течение 40 эпох с оптимизатором _AdamW_. В качестве метрики мы использовали [коэффициент Жаккара _(IoU)_](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D1%8D%D1%84%D1%84%D0%B8%D1%86%D0%B8%D0%B5%D0%BD%D1%82_%D0%96%D0%B0%D0%BA%D0%BA%D0%B0%D1%80%D0%B0).

Сведём данные по значениям метрики IoU на последних эпохах обучения для всех функций потерь.

| Модель | Функция потерь | IoU (train) | IoU (valid) |
| ------ | -------------- | ----------- | ----------- |
| SegNet | BCE loss       | 0.8291      | 0.7981      |
| SegNet | Dice loss      | 0.7965      | 0.7892      |
| SegNet | Focal loss     | 0.8061      | 0.7680      |
| SegNet | WSR loss       | 0.7587      | 0.8007      |

Видно, что для всех функций потерь удалось достичь достаточно неплохих значений метрики _IoU_. Наилучшие результаты показала модель с функцией потерь WSR loss, однако результаты в целом различаются не очень сильно.

Из построенных в рамках проекта графиков видно, что 40 эпох хватило, чтобы достичь сходимости для всех функций потерь. При этом стоит отметить, что для функции потерь _Dice loss_ значения на графиках сходились стабильнее всего.

Также мы обучили несколько моделей с различными вариациями архитектуры [_U-Net_](https://arxiv.org/abs/1505.04597).

Первую модель мы реализовали в соответствии с оригинальной статьёй. Для пулинга (уменьшения размера изображений внутри сети) использовался _MaxPooling_, для апсамплинга (увеличения размера изображений внутри сети) - слои с обратной свёрткой _(ConvTranspose)_.

Во второй модели для пулинга также использовался _MaxPooling_, а для апсмаплинга был применён _nearest-neighbor Upsampling_.

В третьей модели для пулинга были применены свёрточные слои.

Все три модели обучались с функцией потерь BCE. Для каждой модели рассчитывался коэффициент _IoU_.

Сведём результаты экспериментов с U-Net в единую таблицу.

| Модель             | Функция потерь | IoU (train) | IoU (valid) |
| ------------------ | -------------- | ----------- | ----------- |
| U-Net              | BCE loss       | 0.8668      | 0.8016      |
| U-Net + upsampling | BCE loss       | 0.8197      | 0.8299      |
| U-Net + convpool   | BCE loss       | 0.7938      | 0.8327      |

Видно, что в рамках наших экспериментов значения метрики _IoU_ для различных модификаций архитектуры _U-Net_ несколько выше, чем для модели _SegNet_. Наилучшего значения метрики на валидации удалось добиться при использовании свёрточного пуллинга.

Модели на основе _U-Net_ показывают достаточно высокие значения метрики _IoU_, но они сходятся несколько хуже моделей на основе архитектуры _SegNet_. Наилучшую сходимость показала модель со свёрточным пуллингом.

Из проведённых экспериментов видно, что на результаты модели оказывают существенное влияние различные факторы, в том числе выбор функции потерь и нюансов архитектуры. При их выборе следует учитывать несколько факторов: наилучшие значения метрики, стабильность сходимости модели, скорость обучения (количество обучаемых параметров модели). В рамках нашей задачи, если предположить, что заказчику важнее всего значение метрики _IoU_, наилучший результат продемонстрировала модель на основе архитектуры _U-Net_ со свёрточным пуллингом.

В качестве модели мы выбрали [_ResNext_](https://arxiv.org/abs/1611.05431). Данная модификация архитектуры _RexNet_ была предложена в 2017 году и продемонстрировала хорошие результаты на соревновании _ImageNet_. В качестве направления дальнейшего развития данного проекта можно попробовать обучить модели с различными архитектурами (_DenseNet_, _ElasticNet_ и т.д.) и сравнить их результаты.

Обучение происходило с оптимизатором _AdamW_ в течение 20 эпох. В качестве функции потерь была выбрана кросс-энтропия.

На каждой эпохе обучения мы фиксировали значение функции потерь и метрики _F1_.

После обучения мы получили предсказания на тестовых данных и загрузили их на платформу _kaggle_. Результирующее значение метрики _F1_ на тестовой выборке (0.993) соответствует максимальному балу за данную задачу.
